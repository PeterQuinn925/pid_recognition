{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fc9067-e714-46e0-bb69-e5156f8607eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#install stuff\n",
    "# IMPORTANT NOTE: before starting Jupyter Notebook, navigate to /home/peter/Desktop/yolov5. Do source .venv/bin/activate\n",
    "# this sets up the virtual environment where torch is installed and allows yolo to work.\n",
    "# if installing this fresh, you'll need to install torch with Cuda (or not depending on the hardware)\n",
    "#Yolov5\n",
    "%cd /home/peter/Desktop/yolov5\n",
    "! source .venv/bin/activate\n",
    "!uv pip install seaborn\n",
    "!uv pip install gitpython>=3.1.30\n",
    "!uv pip install matplotlib>=3.3\n",
    "!uv pip install numpy>=1.23.5\n",
    "!uv pip install opencv-python>=4.1.1\n",
    "!uv pip install pillow>=10.3.0\n",
    "!uv pip install psutil  # system resources\n",
    "!uv pip install PyYAML>=5.3.1\n",
    "!uv pip install requests>=2.32.2\n",
    "!uv pip install scipy>=1.4.1\n",
    "!uv pip install hop>=0.1.1  # FLOPs computation\n",
    "!uv pip install torch>=1.8.0  # see https://pytorch.org/get-started/locally (recommended)\n",
    "!uv pip install torchvision>=0.9.0\n",
    "!uv pip install tqdm>=4.66.3\n",
    "!uv pip install ultralytics>=8.2.64  # https://ultralytics.com\n",
    "!uv pip install pandas>=1.1.4\n",
    "!uv pip install seaborn>=0.11.0\n",
    "# assume the files are in the right places. See https://github.com/ch-hristov/p-id-symbols for details. Follow the notebook\n",
    "#Ollama\n",
    "!uv pip install ollama\n",
    "#Claude\n",
    "!uv pip install anthropic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecb1899-ec00-4726-9547-2c513502f327",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#yolo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import platform\n",
    "import sys\n",
    "# import torch ***this one is trouble\n",
    "\n",
    "#ollama\n",
    "import ollama\n",
    "import base64\n",
    "# import os duplicate\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "#Claude\n",
    "import anthropic\n",
    "\n",
    "#image handling\n",
    "import os\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import fitz  # PyMuPDF\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63268694-1e2f-4c93-a848-0f81539af88e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Anthropic key - do not publish\n",
    "key=\"sk-ant-api03-cXredactedDHYsswAA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d5810a-49f6-46d1-ba7e-e9d7d0695fb6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Split P&ID into 4 quadrants\n",
    "\n",
    "def pdf_to_images(pdf_path, page_number=0, dpi=300):\n",
    "    \"\"\"\n",
    "    Convert a PDF page to a high-quality PIL Image\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        page_number (int): Page number to convert (0-indexed)\n",
    "        dpi (int): Resolution for the conversion\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image: The converted page as an image\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    if page_number >= len(doc):\n",
    "        raise ValueError(f\"Page {page_number} doesn't exist. PDF has {len(doc)} pages.\")\n",
    "    \n",
    "    page = doc[page_number]\n",
    "    \n",
    "    # Create a transformation matrix for higher resolution\n",
    "    mat = fitz.Matrix(dpi/72, dpi/72)  # 72 is the default DPI\n",
    "    \n",
    "    # Render the page as a pixmap\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    img_data = pix.tobytes(\"png\")\n",
    "    image = Image.open(io.BytesIO(img_data))\n",
    "    \n",
    "    doc.close()\n",
    "    return image\n",
    "\n",
    "def split_image_into_quadrants(image):\n",
    "    \"\"\"\n",
    "    Split a PIL Image into 4 equal quadrants\n",
    "    \n",
    "    Args:\n",
    "        image (PIL.Image): The source image\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Four PIL Images representing the quadrants (top-left, top-right, bottom-left, bottom-right)\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    \n",
    "    # Calculate quadrant dimensions\n",
    "    half_width = width // 2\n",
    "    half_height = height // 2\n",
    "    \n",
    "    # Define crop boxes for each quadrant\n",
    "    # (left, top, right, bottom)\n",
    "    top_left = (0, 0, half_width, half_height)\n",
    "    top_right = (half_width, 0, width, half_height)\n",
    "    bottom_left = (0, half_height, half_width, height)\n",
    "    bottom_right = (half_width, half_height, width, height)\n",
    "    \n",
    "    # Crop the image into quadrants\n",
    "    quadrants = (\n",
    "        image.crop(top_left),\n",
    "        image.crop(top_right),\n",
    "        image.crop(bottom_left),\n",
    "        image.crop(bottom_right)\n",
    "    )\n",
    "    \n",
    "    return quadrants\n",
    "\n",
    "def save_quadrants_as_png(quadrants, output_dir, base_filename):\n",
    "    \"\"\"\n",
    "    Save quadrant images as PNG files\n",
    "    \n",
    "    Args:\n",
    "        quadrants (tuple): Four PIL Images\n",
    "        output_dir (str): Directory to save the images\n",
    "        base_filename (str): Base name for the output files\n",
    "    \n",
    "    Returns:\n",
    "        list: Paths to the saved PNG files\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    quadrant_names = [\"top_left\", \"top_right\", \"bottom_left\", \"bottom_right\"]\n",
    "    saved_paths = []\n",
    "    \n",
    "    for i, (quadrant, name) in enumerate(zip(quadrants, quadrant_names)):\n",
    "        filename = f\"{base_filename}_q{i+1}.png\"\n",
    "#        filename = f\"{base_filename}_quadrant_{i+1}_{name}.png\"\n",
    "        filepath = output_dir / filename\n",
    "        \n",
    "        # Save as PNG with high quality\n",
    "        quadrant.save(filepath, \"PNG\", optimize=True)\n",
    "        saved_paths.append(str(filepath))\n",
    "#        print(f\"Saved quadrant {i+1} ({name}): {filepath}\")\n",
    "    \n",
    "    return saved_paths\n",
    "    \n",
    "def create_quads(pdf_path,page,output_dir):\n",
    "     image = pdf_to_images(pdf_path, page)\n",
    "     quadrants = split_image_into_quadrants(image)\n",
    "# Save quadrants as PNG files\n",
    "     base_filename = Path(pdf_path).stem\n",
    "     quadrant_paths = save_quadrants_as_png(quadrants, output_dir, base_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f604a422-9323-439d-a9f7-bbf0047b5969",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# call Ollama LLMs. Encode PNGs too.\n",
    "def encode_png_file(png_path: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Encode a PNG file to base64\n",
    "    \n",
    "    Args:\n",
    "        png_path (str): Path to the PNG file\n",
    "    \n",
    "    Returns:\n",
    "        str: Base64 encoded image data, or None if error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(png_path, 'rb') as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding {png_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def find_png_files(directory: str, pattern: str = \"*.png\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Find all PNG files in a directory\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Directory to search\n",
    "        pattern (str): File pattern (default: \"*.png\")\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of PNG file paths\n",
    "    \"\"\"\n",
    "    search_path = os.path.join(directory, pattern)\n",
    "    png_files = glob.glob(search_path)\n",
    "    png_files.sort()  # Sort for consistent ordering\n",
    "    return png_files\n",
    "\n",
    "def query_ollama(model, prompt, png_path,output_type):\n",
    "    if png_path != \"\": \n",
    "        encoded_image = encode_png_file(png_path)\n",
    "    \n",
    "        response = ollama.chat(\n",
    "           model=model,\n",
    "           messages=[{'role': 'user', 'content': prompt,'images': [encoded_image]}],\n",
    "           options={\n",
    "               'temperature': 0.7,  # Range: 0.0 to 1.0\n",
    "           }\n",
    "        )\n",
    "    else:\n",
    "        response = ollama.chat(\n",
    "           model=model,\n",
    "           messages=[{'role': 'user', 'content': prompt}],\n",
    "           options={\n",
    "                'temperature': 0.7,  # Range: 0.0 to 1.0\n",
    "           }\n",
    "        )\n",
    "    if output_type == \"\" or output_type.upper() == 'JSON':\n",
    "        foo = response.message.content[8:-4]\n",
    "        #print(response.message.content)\n",
    "        output = json.loads(foo)\n",
    "    else: #just return text\n",
    "        output = response\n",
    "    return output\n",
    "\n",
    "def query_ollama_multiple(model, prompt, png_path): #same as above, except png_path is a list of pngs\n",
    "    #!!!!!This does not work. Right now ollama does not support multiple images\n",
    "    encoded_images = []\n",
    "    \n",
    "    for i,png in enumerate(png_path):\n",
    "       encoded_images.append(encode_png_file(png))\n",
    "   \n",
    "    response = ollama.chat(\n",
    "       model=model,\n",
    "       messages=[{'role': 'user', 'content': prompt,'images': [encoded_images]}],\n",
    "       options={\n",
    "           'temperature': 0.7,  # Range: 0.0 to 1.0\n",
    "       }\n",
    "    )\n",
    "\n",
    "    foo = response.message.content[8:-4]\n",
    "    response_J = json.loads(foo)\n",
    "    return response_J    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "034780ff-bc32-417f-9c1e-35a47ea5a238",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Claude\n",
    "Claude = \"claude-sonnet-4-20250514\"\n",
    "\n",
    "#initialize\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=key  # or set ANTHROPIC_API_KEY environment variable\n",
    ")\n",
    "\n",
    "def claude_simple(prompt_text):\n",
    "    content = []\n",
    "    content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": prompt_text\n",
    "    })\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=Claude,\n",
    "        max_tokens=2000,\n",
    "        temperature = 0.5,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }]\n",
    "    )\n",
    "    return message.content[0].text \n",
    "\n",
    "def upload_multiple_images_to_claude(image_paths, prompt_text):\n",
    "    \"\"\"\n",
    "    Upload multiple images to Claude\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of paths to image files\n",
    "        prompt_text (str): Text prompt to send along with the images\n",
    "    \n",
    "    Returns:\n",
    "        str: Claude's response\n",
    "    \"\"\"\n",
    "    \n",
    "    content = []\n",
    "    \n",
    "    # Add all images\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        image_path = Path(image_path)\n",
    "        \n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        \n",
    "        content.append({\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "                \"type\": \"base64\",\n",
    "                \"media_type\": \"image/png\",\n",
    "                \"data\": image_data\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Add text prompt\n",
    "    content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": prompt_text\n",
    "    })\n",
    "    \n",
    "    message = client.messages.create(\n",
    "        model=Claude,\n",
    "        max_tokens=2000,\n",
    "        temperature = 0.5,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6daefdd6-baa8-47cc-9510-df6afd5d7749",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cropping YOLO predictions\n",
    "def crop_predictions(png_file_path, predictions_csv_path, scaling_factor=1.0, output_dir=\"cropped_images\"):\n",
    "    \"\"\"\n",
    "    Crop image regions based on predictions CSV with bounding box coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    png_file_path (str): Path to the input PNG image\n",
    "    predictions_csv_path (str): Path to the predictions CSV file\n",
    "    scaling_factor (float): Factor to scale the bounding box size (1.0 = original size)\n",
    "    output_dir (str): Directory to save cropped images\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(predictions_csv_path)\n",
    "    \n",
    "    # Load the image\n",
    "    image = Image.open(png_file_path)\n",
    "    image_width, image_height = image.size\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get the base name of the PNG file (without extension)\n",
    "    base_name = Path(png_file_path).stem\n",
    "    \n",
    "    cropped_images = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Parse the xyxy coordinates from string representation\n",
    "        # Remove 'tensor()' wrapper and convert to float\n",
    "        coords_str = row['Xyxy'].strip('[]').replace(\" device='cuda:0'),\",\"\")\n",
    "        coords_parts = coords_str.split(', ')\n",
    "        if len(coords_parts)>4: # there is extra garbage on the end, remove it\n",
    "            del coords_parts[-1]\n",
    "        \n",
    "        # Extract numerical values from tensor format\n",
    "        coords = []\n",
    "        for part in coords_parts:\n",
    "            # Remove 'tensor(' and ')' and convert to float\n",
    "            num_str = part.strip().replace('tensor(', '').replace(')', '').replace('.', '')\n",
    "            coords.append(float(num_str))\n",
    "        \n",
    "        x1, y1, x2, y2 = coords\n",
    "        \n",
    "        # Calculate center and dimensions of bounding box\n",
    "        center_x = (x1 + x2) / 2\n",
    "        center_y = (y1 + y2) / 2\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "        \n",
    "        # Apply scaling factor\n",
    "        scaled_width = width * scaling_factor\n",
    "        scaled_height = height * scaling_factor\n",
    "        \n",
    "        # Calculate new coordinates\n",
    "        new_x1 = center_x - scaled_width / 2\n",
    "        new_y1 = center_y - scaled_height / 2\n",
    "        new_x2 = center_x + scaled_width / 2\n",
    "        new_y2 = center_y + scaled_height / 2\n",
    "        \n",
    "        # Ensure coordinates are within image bounds\n",
    "        new_x1 = max(0, min(new_x1, image_width))\n",
    "        new_y1 = max(0, min(new_y1, image_height))\n",
    "        new_x2 = max(0, min(new_x2, image_width))\n",
    "        new_y2 = max(0, min(new_y2, image_height))\n",
    "        \n",
    "        # Crop the image\n",
    "        cropped_img = image.crop((new_x1, new_y1, new_x2, new_y2))\n",
    "        \n",
    "        # Create filename for cropped image\n",
    "        prediction_clean = row['Prediction']\n",
    "        confidence = f\"{row['Confidence']:.2f}\"\n",
    "        output_filename = f\"{base_name}_{idx:03d}_{prediction_clean}_conf{confidence}.png\"\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        # Save cropped image\n",
    "        cropped_img.save(output_path)\n",
    "        \n",
    "        cropped_images.append({\n",
    "            'index': idx,\n",
    "            'prediction': row['Prediction'],\n",
    "            'confidence': row['Confidence'],\n",
    "            'original_coords': (x1, y1, x2, y2),\n",
    "            'scaled_coords': (new_x1, new_y1, new_x2, new_y2),\n",
    "            'output_path': output_path,\n",
    "            'size': cropped_img.size\n",
    "        })\n",
    "        \n",
    "        print(f\"Saved: {output_filename} ({cropped_img.size[0]}x{cropped_img.size[1]})\")\n",
    "    \n",
    "    print(f\"\\nProcessed {len(cropped_images)} predictions\")\n",
    "    print(f\"Cropped images saved to: {output_dir}\")\n",
    "    \n",
    "    return cropped_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aa6f80f-df86-4887-b5ab-c75aff351dc7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "valve_classes = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "inst_classes = [26,27,28,29,31]\n",
    "def class_lookup(prediction):\n",
    "    res = \"unknown\" # if not a match\n",
    "    match prediction:\n",
    "        case 1:\n",
    "            res = \"Gate_Valve\"\n",
    "        case 2:\n",
    "            res = \"Ball_Valve\"\n",
    "        case 3:\n",
    "            res = \"Globe_valve_NO\"\n",
    "        case 4: \n",
    "            res = \"Gate_valve_NO\"\n",
    "        case 5: \n",
    "            res = \"Globe_valve_NO\"\n",
    "        case 6: \n",
    "            res = \"Butterfly_Valve\"\n",
    "        case 7: \n",
    "            res = \"Plug Valve\"\n",
    "        case 8: \n",
    "            res = \"Check_Valve\"\n",
    "        case 9: \n",
    "            res = \"Diaphragm_valve\"\n",
    "        case 10: \n",
    "            res = \"Needle_valve\"\n",
    "        case 11: \n",
    "            res = \"Half_Filled_Gate_Valve\"\n",
    "        case 12: \n",
    "            res = \"Gate_Valve_NC\"\n",
    "        case 13: \n",
    "            res = \"Globle_valve_NC\"\n",
    "        case 14: \n",
    "            res = \"Control_Valve\"\n",
    "        case 15:\n",
    "            res = \"Rotary_Valve\"\n",
    "        case 16: \n",
    "            res = \"Ball_valve_NC\"\n",
    "        case 17:\n",
    "            res = \"Paddle_blind\"\n",
    "        case 18: \n",
    "            res = \"Spectacle_blind_Closed\"\n",
    "        case 19: \n",
    "            res = \"Spectacle_blind_Open\"\n",
    "        case 20: \n",
    "            res = \"Reducer\"\n",
    "        case 21:\n",
    "            res = \"Flange_or_Nozzle\"\n",
    "        case 22: \n",
    "            res = \"Rupture_disk\"\n",
    "        case 23: \n",
    "            res = \"Pipe_Insulation_or_Tracing\"\n",
    "        case 24:\n",
    "            res = \"Flow_Arrow\"\n",
    "        case 25:\n",
    "            res = \"sight_glass\"\n",
    "        case 26:\n",
    "            res = \"Instrument_Field\"\n",
    "        case 27: \n",
    "            res = \"Instrument_Field\"\n",
    "        case 28: \n",
    "            res = \"Instrument_Panel\"\n",
    "        case 29:\n",
    "            res = \"Instrument_Aux_Panel\"\n",
    "        case 30:\n",
    "            res = \"box\"\n",
    "        case 31:\n",
    "            res = \"Instrument_Panel\"\n",
    "        case 32:\n",
    "            res = \"box\"\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a2ac6c1-d49c-4493-923a-2e8580605b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_valves_instruments(flavor,resultslist,full_dwg,detect_path):\n",
    "# flavor = \"valve\" or \"inst\"\n",
    "# resultlist is the list of valves or instruments to return\n",
    "# classlist is the list of valve or instrument predictions valve_classlist or inst_classlist, depending on the \"flavor\"\n",
    "# scale will also be defined as 1.1 for inst and 8.0 for valves\n",
    "    if flavor == \"valve\":\n",
    "        scale = 8\n",
    "        classlist = valve_classes\n",
    "    elif flavor == \"inst\":\n",
    "        scale = 1.1\n",
    "        classlist = inst_classes\n",
    "    else:\n",
    "        print (\"error, undefined flavor, must be inst or valve\")\n",
    "        return\n",
    "    for quad in range(4):\n",
    "        #image size is important - if the size is too far off, detection is not accurate\n",
    "        #using cpu because otherwise out of memory issues intermittently. Speed difference is not material\n",
    "        run_path = '\"./detect.py\" --weights \"./best.pt\" --source '+full_dwg[quad]+' --conf-thres 0.5 --save-csv --imgsz 5000 --device cpu'\n",
    "        %run {run_path}\n",
    "        result_path = detect_path+\"/exp\"\n",
    "        if quad>0:\n",
    "            result_path = result_path+str(quad+1)\n",
    "        #create cropped images. scale needs to be big for valves, small for instruments\n",
    "        crop_predictions(full_dwg[quad], result_path+\"/predictions.csv\", scaling_factor=scale, output_dir=result_path)\n",
    "        #go through each detected item and add the ones we want to the valve list\n",
    "            # Read the CSV file\n",
    "        df = pd.read_csv(result_path+\"/predictions.csv\")\n",
    "        base_name = Path(full_dwg[quad]).stem\n",
    "        for idx, row in df.iterrows():\n",
    "            # Parse the xyxy coordinates from string representation\n",
    "            # Remove 'tensor()' wrapper and convert to float\n",
    "            coords_str = row['Xyxy'].strip('[]').replace(\" device='cuda:0'),\",\"\")\n",
    "            coords_parts = coords_str.split(', ')\n",
    "            if len(coords_parts)>4: # there is extra garbage on the end, remove it\n",
    "                del coords_parts[-1]\n",
    "            prediction = row['Prediction']\n",
    "            #Prediction holds an int containing the type of item found. We only want certain types\n",
    "            if prediction in classlist: # this is a valve (or this is an instrument)\n",
    "                classname = class_lookup(prediction)\n",
    "                # Extract numerical values from tensor format to get the valve center coordinates\n",
    "                coords = []\n",
    "                for part in coords_parts:\n",
    "                # Remove 'tensor(' and ')' and convert to float\n",
    "                    num_str = part.strip().replace('tensor(', '').replace(')', '').replace('.', '')\n",
    "                    coords.append(float(num_str))\n",
    "                x1, y1, x2, y2 = coords\n",
    "                # Calculate center and dimensions of bounding box\n",
    "                center_x = (x1 + x2) / 2\n",
    "                center_y = (y1 + y2) / 2\n",
    "                #Get the image filename and send it to a LLM to get the size and tag number\n",
    "                # reCreate filename for cropped image\n",
    "                prediction_clean = row['Prediction']\n",
    "                confidence = f\"{row['Confidence']:.2f}\"\n",
    "                output_filename = f\"{base_name}_{idx:03d}_{prediction_clean}_conf{confidence}.png\"\n",
    "                png_path = os.path.join(result_path, output_filename)\n",
    "                if flavor == \"valve\":\n",
    "                    prompt = \"\"\"Look at the valve in the center of the image. Return the valve size and valve tag number as a \n",
    "                    json string. If either value can't be found return the value as none\"\"\"\n",
    "                    result = query_ollama(ollama_model, prompt, png_path,\"JSON\")\n",
    "                    valve_size=\"\"\n",
    "                    valve_tag=\"\"\n",
    "                    try:\n",
    "                       valve_size = result[\"valve_size\"]\n",
    "                       valve_tag = result[\"valve_tag_number\"]\n",
    "                    except KeyError as e:\n",
    "                        valve_tag = result[\"valve_tag\"]\n",
    "                    except:\n",
    "                        print(\"error:\",result)\n",
    "#FUTURE: try to get the line number of the valve too\n",
    "                    valvedict = {\"tag\": valve_tag, \"type\": classname, \"size\": valve_size, \"center_x\": center_x, \"center_y\": center_y}\n",
    "                    resultslist.append(valvedict)\n",
    "                else:\n",
    "                    prompt = \"\"\"Look at the instrument in the center of the image. The instrument tag type is the top text\n",
    "                    and the instrument number is the bottom text. Return a JSON string of top and bottom text with the keys top and bottom\"\"\"\n",
    "                    result = query_ollama(ollama_model, prompt, png_path,\"JSON\")\n",
    "                    print(result)\n",
    "                    top=\"\"\n",
    "                    bottom=\"\"\n",
    "                    try:\n",
    "                        top = result[\"top\"]\n",
    "                        bottom = result[\"bottom\"]\n",
    "                        inst_tag = str(top) + \"-\" + str(bottom)\n",
    "                    except KeyError as e:\n",
    "                        inst_tag = top+bottom\n",
    "                    except:\n",
    "                        print(\"error:\",result)\n",
    "\n",
    "                    instdict = {\"tag\": inst_tag, \"type\": classname, \"center_x\": center_x, \"center_y\": center_y}\n",
    "                    resultslist.append(instdict)\n",
    "    return resultslist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9fcf2d0b-940f-446f-ad3e-0cbc9d2ec594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "class DEXPIGenerator:\n",
    "    \"\"\"Generate DEXPI 1.4 compliant XML files\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.namespaces = {\n",
    "            'xsi': 'http://www.w3.org/2001/XMLSchema-instance',\n",
    "            'dexpi': 'http://www.dexpi.org/rdl',\n",
    "            '': 'http://www.dexpi.org/schema/dexpi'\n",
    "        }\n",
    "        \n",
    "    def create_dexpi_xml(self, pipes=None, equipment=None, valves=None, instruments=None, \n",
    "                         drawing_metadata=None):\n",
    "        \"\"\"\n",
    "        Create DEXPI XML structure\n",
    "        \n",
    "        Args:\n",
    "            pipes: Dict with pipe info (single pipe or dict of pipes by ID/tag)\n",
    "            equipment: Dict with equipment info (single equipment or dict of equipment by ID/tag)\n",
    "            valves: List of dicts with valve info\n",
    "            instruments: List of dicts with instrument info\n",
    "            drawing_metadata: Dict with drawing information (project_name, drawing_number, etc.)\n",
    "        \"\"\"\n",
    "        # Register namespaces\n",
    "        for prefix, uri in self.namespaces.items():\n",
    "            ET.register_namespace(prefix, uri)\n",
    "        \n",
    "        # Create root element\n",
    "        root = ET.Element('PlantModel', attrib={\n",
    "            '{http://www.w3.org/2001/XMLSchema-instance}schemaLocation': \n",
    "                'http://www.dexpi.org/schema/dexpi DEXPI_Proteus_v1.4.xsd',\n",
    "            'SchemaVersion': '1.4'\n",
    "        })\n",
    "        \n",
    "        # Add PlantInformation\n",
    "        self._add_plant_information(root, drawing_metadata)\n",
    "        \n",
    "        # Create PlantStructure\n",
    "        plant_structure = ET.SubElement(root, 'PlantStructure')\n",
    "        \n",
    "        # Add Equipment (convert dict to list if needed)\n",
    "        if equipment:\n",
    "            equip_list = self._normalize_to_list(equipment)\n",
    "            self._add_equipment(plant_structure, equip_list)\n",
    "        \n",
    "        # Add Piping (convert dict to list if needed)\n",
    "        if pipes:\n",
    "            pipe_list = self._normalize_to_list(pipes)\n",
    "            self._add_pipes(plant_structure, pipe_list)\n",
    "        \n",
    "        # Add Valves (already a list)\n",
    "        if valves:\n",
    "            self._add_valves(plant_structure, valves)\n",
    "        \n",
    "        # Add Instruments (already a list)\n",
    "        if instruments:\n",
    "            self._add_instruments(plant_structure, instruments)\n",
    "        \n",
    "        # Add Drawing section if metadata provided\n",
    "        if drawing_metadata:\n",
    "            self._add_drawing_information(root, drawing_metadata)\n",
    "        \n",
    "        return root\n",
    "    \n",
    "    def _add_plant_information(self, root, metadata):\n",
    "        \"\"\"Add plant information section\"\"\"\n",
    "        plant_info = ET.SubElement(root, 'PlantInformation')\n",
    "        plant_id = ET.SubElement(plant_info, 'PlantIdentification')\n",
    "        \n",
    "        if metadata:\n",
    "            # Use project_name or company_name as ProjectIdentifier\n",
    "            project = metadata.get('project_name') or metadata.get('company_name') or 'Unknown Project'\n",
    "            ET.SubElement(plant_id, 'ProjectIdentifier').text = project\n",
    "            \n",
    "            # Use location or drawing_number as PlantIdentifier\n",
    "            plant = metadata.get('location') or metadata.get('drawing_number') or 'Unknown Plant'\n",
    "            ET.SubElement(plant_id, 'PlantIdentifier').text = plant\n",
    "            \n",
    "            # Add company info if available\n",
    "            if metadata.get('company_name'):\n",
    "                owner = ET.SubElement(plant_info, 'Owner')\n",
    "                ET.SubElement(owner, 'Name').text = metadata['company_name']\n",
    "        else:\n",
    "            ET.SubElement(plant_id, 'ProjectIdentifier').text = 'Unknown Project'\n",
    "            ET.SubElement(plant_id, 'PlantIdentifier').text = 'Unknown Plant'\n",
    "        \n",
    "        # Add creation timestamp\n",
    "        timestamp = ET.SubElement(plant_info, 'TimeStamp')\n",
    "        ET.SubElement(timestamp, 'DateTime').text = datetime.utcnow().isoformat() + 'Z'\n",
    "    \n",
    "    def _is_single_item(self, data):\n",
    "        \"\"\"Check if dict represents a single item (has 'tag' or 'id' key) vs dict of items\"\"\"\n",
    "        return 'tag' in data or 'id' in data or 'name' in data\n",
    "    \n",
    "    def _normalize_to_list(self, data):\n",
    "        \"\"\"Convert various data structures to a flat list of items\"\"\"\n",
    "        if data is None:\n",
    "            return []\n",
    "        \n",
    "        # Already a list\n",
    "        if isinstance(data, list):\n",
    "            # Flatten if it's a list of lists\n",
    "            result = []\n",
    "            for item in data:\n",
    "                if isinstance(item, list):\n",
    "                    result.extend(item)\n",
    "                else:\n",
    "                    result.append(item)\n",
    "            return result\n",
    "        \n",
    "        # Single dictionary item (has tag/id/name keys)\n",
    "        if isinstance(data, dict):\n",
    "            if self._is_single_item(data):\n",
    "                return [data]\n",
    "            else:\n",
    "                # Dictionary of items keyed by tag/id\n",
    "                return list(data.values())\n",
    "        \n",
    "        # Single item of unknown type\n",
    "        return [data]\n",
    "    \n",
    "    def _add_drawing_information(self, root, metadata):\n",
    "        \"\"\"Add drawing-specific information\"\"\"\n",
    "        drawing_section = ET.SubElement(root, 'Drawing')\n",
    "        drawing_section.set('ID', f\"DRW-{uuid.uuid4().hex[:8]}\")\n",
    "        \n",
    "        # Drawing identification\n",
    "        if metadata.get('drawing_number'):\n",
    "            ET.SubElement(drawing_section, 'DrawingNumber').text = metadata['drawing_number']\n",
    "        \n",
    "        if metadata.get('drawing_name'):\n",
    "            ET.SubElement(drawing_section, 'DrawingName').text = metadata['drawing_name']\n",
    "        \n",
    "        if metadata.get('revision'):\n",
    "            ET.SubElement(drawing_section, 'Revision').text = metadata['revision']\n",
    "        \n",
    "        # Date information\n",
    "        if metadata.get('date'):\n",
    "            date_elem = ET.SubElement(drawing_section, 'DrawingDate')\n",
    "            ET.SubElement(date_elem, 'Date').text = metadata['date']\n",
    "        \n",
    "        # Author/creator information\n",
    "        if metadata.get('author'):\n",
    "            creator = ET.SubElement(drawing_section, 'Creator')\n",
    "            ET.SubElement(creator, 'Name').text = metadata['author']\n",
    "        \n",
    "        # Additional drawing attributes\n",
    "        if metadata.get('additional_information'):\n",
    "            attrs = ET.SubElement(drawing_section, 'GenericAttributes')\n",
    "            for i, info in enumerate(metadata['additional_information']):\n",
    "                if info.strip():  # Skip empty lines\n",
    "                    attr = ET.SubElement(attrs, 'GenericAttribute')\n",
    "                    attr.set('Name', f'AdditionalInfo_{i+1}')\n",
    "                    attr.set('Value', info)\n",
    "        \n",
    "        # Add scale if found in additional info\n",
    "        for info in metadata.get('additional_information', []):\n",
    "            if 'SCALE' in info.upper():\n",
    "                ET.SubElement(drawing_section, 'Scale').text = info\n",
    "                break\n",
    "        \n",
    "        # Add sheet info if found\n",
    "        for info in metadata.get('additional_information', []):\n",
    "            if 'SHEET' in info.upper():\n",
    "                ET.SubElement(drawing_section, 'SheetInfo').text = info\n",
    "                break\n",
    "    \n",
    "    def _add_equipment(self, parent, equipment_list):\n",
    "        \"\"\"Add equipment elements\"\"\"\n",
    "        if not equipment_list:\n",
    "            return\n",
    "            \n",
    "        for eq in equipment_list:\n",
    "            # Skip if not a dict\n",
    "            if not isinstance(eq, dict):\n",
    "                continue\n",
    "                \n",
    "            equipment = ET.SubElement(parent, 'Equipment')\n",
    "            equipment.set('ID', eq.get('id', f\"EQ-{uuid.uuid4().hex[:8]}\"))\n",
    "            equipment.set('ComponentClass', eq.get('class', 'GenericEquipment'))\n",
    "            equipment.set('ComponentName', eq.get('name', eq.get('tag', 'Equipment')))\n",
    "            \n",
    "            # Add tag name\n",
    "            if 'tag' in eq:\n",
    "                ET.SubElement(equipment, 'TagName').text = eq['tag']\n",
    "            \n",
    "            # Add description\n",
    "            if 'description' in eq:\n",
    "                ET.SubElement(equipment, 'Description').text = eq['description']\n",
    "            \n",
    "            # Add attributes\n",
    "            if 'attributes' in eq:\n",
    "                attrs = ET.SubElement(equipment, 'GenericAttributes')\n",
    "                for key, value in eq['attributes'].items():\n",
    "                    attr = ET.SubElement(attrs, 'GenericAttribute')\n",
    "                    attr.set('Name', key)\n",
    "                    attr.set('Value', str(value))\n",
    "            \n",
    "            # Add connections (nozzles)\n",
    "            if 'connections' in eq:\n",
    "                for conn in eq['connections']:\n",
    "                    nozzle = ET.SubElement(equipment, 'Nozzle')\n",
    "                    nozzle.set('ID', conn.get('id', f\"N-{uuid.uuid4().hex[:8]}\"))\n",
    "                    nozzle.set('ComponentName', conn.get('name', 'Nozzle'))\n",
    "    \n",
    "    def _add_pipes(self, parent, pipe_list):\n",
    "        \"\"\"Add piping elements\"\"\"\n",
    "        if not pipe_list:\n",
    "            return\n",
    "            \n",
    "        for pipe in pipe_list:\n",
    "            # Skip if not a dict\n",
    "            if not isinstance(pipe, dict):\n",
    "                continue\n",
    "                \n",
    "            pipe_elem = ET.SubElement(parent, 'PipingNetworkSegment')\n",
    "            pipe_elem.set('ID', pipe.get('id', f\"P-{uuid.uuid4().hex[:8]}\"))\n",
    "            pipe_elem.set('ComponentName', pipe.get('name', pipe.get('tag', 'Pipe')))\n",
    "            \n",
    "            # Add tag name\n",
    "            if 'tag' in pipe:\n",
    "                ET.SubElement(pipe_elem, 'TagName').text = pipe['tag']\n",
    "            \n",
    "            # Add nominal diameter\n",
    "            if 'diameter' in pipe:\n",
    "                attr = ET.SubElement(pipe_elem, 'NominalDiameter')\n",
    "                attr.set('Value', str(pipe['diameter']))\n",
    "                attr.set('Units', pipe.get('diameter_units', 'mm'))\n",
    "            \n",
    "            # Add pipe specification\n",
    "            if 'spec' in pipe:\n",
    "                ET.SubElement(pipe_elem, 'PipeSpec').text = pipe['spec']\n",
    "            \n",
    "            # Add material\n",
    "            if 'material' in pipe:\n",
    "                ET.SubElement(pipe_elem, 'Material').text = pipe['material']\n",
    "            \n",
    "            # Add service description\n",
    "            if 'service' in pipe:\n",
    "                ET.SubElement(pipe_elem, 'ServiceDescription').text = pipe['service']\n",
    "            \n",
    "            # Add pressure rating\n",
    "            if 'pressure_rating' in pipe:\n",
    "                attr = ET.SubElement(pipe_elem, 'PressureRating')\n",
    "                attr.set('Value', str(pipe['pressure_rating']))\n",
    "                attr.set('Units', pipe.get('pressure_units', 'bar'))\n",
    "            \n",
    "            # Add connections\n",
    "            if 'from_connection' in pipe:\n",
    "                conn = ET.SubElement(pipe_elem, 'Connection')\n",
    "                conn.set('ID', f\"C-{uuid.uuid4().hex[:8]}\")\n",
    "                conn.set('ConnectedObjectID', pipe['from_connection'])\n",
    "            \n",
    "            if 'to_connection' in pipe:\n",
    "                conn = ET.SubElement(pipe_elem, 'Connection')\n",
    "                conn.set('ID', f\"C-{uuid.uuid4().hex[:8]}\")\n",
    "                conn.set('ConnectedObjectID', pipe['to_connection'])\n",
    "    \n",
    "    def _add_valves(self, parent, valve_list):\n",
    "        \"\"\"Add valve elements\"\"\"\n",
    "        if not valve_list:\n",
    "            return\n",
    "            \n",
    "        for valve in valve_list:\n",
    "            # Skip if not a dict\n",
    "            if not isinstance(valve, dict):\n",
    "                continue\n",
    "                \n",
    "            valve_elem = ET.SubElement(parent, 'Valve')\n",
    "            valve_elem.set('ID', valve.get('id', f\"V-{uuid.uuid4().hex[:8]}\"))\n",
    "            valve_elem.set('ComponentClass', valve.get('class', 'GenericValve'))\n",
    "            valve_elem.set('ComponentName', valve.get('name', valve.get('tag', 'Valve')))\n",
    "            \n",
    "            # Add tag name\n",
    "            if 'tag' in valve:\n",
    "                ET.SubElement(valve_elem, 'TagName').text = valve['tag']\n",
    "            \n",
    "            # Add valve type\n",
    "            if 'type' in valve:\n",
    "                ET.SubElement(valve_elem, 'ValveType').text = valve['type']\n",
    "            \n",
    "            # Add size\n",
    "            if 'size' in valve:\n",
    "                attr = ET.SubElement(valve_elem, 'NominalDiameter')\n",
    "                attr.set('Value', str(valve['size']))\n",
    "                attr.set('Units', valve.get('size_units', 'mm'))\n",
    "            \n",
    "            # Add actuation\n",
    "            if 'actuation' in valve:\n",
    "                ET.SubElement(valve_elem, 'ActuationType').text = valve['actuation']\n",
    "            \n",
    "            # Add function\n",
    "            if 'function' in valve:\n",
    "                ET.SubElement(valve_elem, 'ValveFunction').text = valve['function']\n",
    "            \n",
    "            # Add connections\n",
    "            for i in range(2):\n",
    "                conn = ET.SubElement(valve_elem, 'Connection')\n",
    "                conn.set('ID', f\"C-{uuid.uuid4().hex[:8]}\")\n",
    "    \n",
    "    def _add_instruments(self, parent, instrument_list):\n",
    "        \"\"\"Add instrument elements\"\"\"\n",
    "        if not instrument_list:\n",
    "            return\n",
    "            \n",
    "        for inst in instrument_list:\n",
    "            # Skip if not a dict\n",
    "            if not isinstance(inst, dict):\n",
    "                continue\n",
    "                \n",
    "            inst_elem = ET.SubElement(parent, 'Instrument')\n",
    "            inst_elem.set('ID', inst.get('id', f\"I-{uuid.uuid4().hex[:8]}\"))\n",
    "            inst_elem.set('ComponentClass', inst.get('class', 'GenericInstrument'))\n",
    "            inst_elem.set('ComponentName', inst.get('name', inst.get('tag', 'Instrument')))\n",
    "            \n",
    "            # Add tag name\n",
    "            if 'tag' in inst:\n",
    "                ET.SubElement(inst_elem, 'TagName').text = inst['tag']\n",
    "            \n",
    "            # Add instrument type\n",
    "            if 'type' in inst:\n",
    "                ET.SubElement(inst_elem, 'InstrumentType').text = inst['type']\n",
    "            \n",
    "            # Add measured variable\n",
    "            if 'measured_variable' in inst:\n",
    "                ET.SubElement(inst_elem, 'MeasuredVariable').text = inst['measured_variable']\n",
    "            \n",
    "            # Add function\n",
    "            if 'function' in inst:\n",
    "                ET.SubElement(inst_elem, 'InstrumentFunction').text = inst['function']\n",
    "            \n",
    "            # Add range\n",
    "            if 'range_min' in inst and 'range_max' in inst:\n",
    "                range_elem = ET.SubElement(inst_elem, 'MeasurementRange')\n",
    "                ET.SubElement(range_elem, 'MinValue').text = str(inst['range_min'])\n",
    "                ET.SubElement(range_elem, 'MaxValue').text = str(inst['range_max'])\n",
    "                if 'range_units' in inst:\n",
    "                    ET.SubElement(range_elem, 'Units').text = inst['range_units']\n",
    "            \n",
    "            # Add process connection\n",
    "            if 'connected_to' in inst:\n",
    "                conn = ET.SubElement(inst_elem, 'ProcessConnection')\n",
    "                conn.set('ConnectedObjectID', inst['connected_to'])\n",
    "    \n",
    "    def save_xml(self, root, filename):\n",
    "        \"\"\"Save XML to file with pretty printing\"\"\"\n",
    "        # Check if root is an Element\n",
    "        if not isinstance(root, ET.Element):\n",
    "            raise ValueError(f\"Expected ET.Element, got {type(root)}. Make sure create_dexpi_xml() returned successfully.\")\n",
    "        \n",
    "        xml_str = ET.tostring(root, encoding='utf-8')\n",
    "        dom = minidom.parseString(xml_str)\n",
    "        pretty_xml = dom.toprettyxml(indent='  ', encoding='utf-8')\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(pretty_xml)\n",
    "        \n",
    "        print(f\"DEXPI XML saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16b2ad-83ed-4582-8f0d-48a7ef667de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5e59e-8b38-4230-b326-b86306b87986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./best.pt'], source=/home/peter/dyn2/dyn2_q1.png, data=data/coco128.yaml, imgsz=[5000, 5000], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=cpu, view_img=False, save_txt=False, save_format=0, save_csv=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.0s\n",
      "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-430-g459d8bf0 Python-3.12.3 torch-2.8.0+cu128 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46280598 parameters, 0 gradients, 108.2 GFLOPs\n",
      "WARNING ⚠️ --img-size [5000, 5000] must be multiple of max stride 32, updating to [5024, 5024]\n",
      "image 1/1 /home/peter/dyn2/dyn2_q1.png: 3904x5024 7 4s, 1 6, 5 12s, 3 15s, 1 16, 1 18, 2 20s, 5 21s, 5 24s, 1 31, 8294.6ms\n",
      "Speed: 14.1ms pre-process, 8294.6ms inference, 10.0ms NMS per image at shape (1, 3, 5024, 5024)\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: dyn2_q1_000_21_conf0.54.png (104x168)\n",
      "Saved: dyn2_q1_001_4_conf0.55.png (128x208)\n",
      "Saved: dyn2_q1_002_20_conf0.55.png (120x112)\n",
      "Saved: dyn2_q1_003_15_conf0.56.png (48x48)\n",
      "Saved: dyn2_q1_004_16_conf0.57.png (18x88)\n",
      "Saved: dyn2_q1_005_15_conf0.58.png (48x48)\n",
      "Saved: dyn2_q1_006_21_conf0.60.png (64x71)\n",
      "Saved: dyn2_q1_007_15_conf0.61.png (56x48)\n",
      "Saved: dyn2_q1_008_24_conf0.63.png (76x136)\n",
      "Saved: dyn2_q1_009_18_conf0.65.png (336x88)\n",
      "Saved: dyn2_q1_010_31_conf0.71.png (54x313)\n",
      "Saved: dyn2_q1_011_24_conf0.74.png (96x168)\n",
      "Saved: dyn2_q1_012_21_conf0.74.png (72x112)\n",
      "Saved: dyn2_q1_013_6_conf0.77.png (208x87)\n",
      "Saved: dyn2_q1_014_4_conf0.81.png (200x120)\n",
      "Saved: dyn2_q1_015_24_conf0.85.png (104x168)\n",
      "Saved: dyn2_q1_016_21_conf0.85.png (112x72)\n",
      "Saved: dyn2_q1_017_12_conf0.86.png (128x208)\n",
      "Saved: dyn2_q1_018_4_conf0.86.png (208x112)\n",
      "Saved: dyn2_q1_019_12_conf0.86.png (120x208)\n",
      "Saved: dyn2_q1_020_24_conf0.87.png (112x184)\n",
      "Saved: dyn2_q1_021_4_conf0.87.png (208x120)\n",
      "Saved: dyn2_q1_022_4_conf0.87.png (208x87)\n",
      "Saved: dyn2_q1_023_4_conf0.87.png (200x87)\n",
      "Saved: dyn2_q1_024_24_conf0.88.png (184x79)\n",
      "Saved: dyn2_q1_025_20_conf0.88.png (112x112)\n",
      "Saved: dyn2_q1_026_4_conf0.88.png (208x87)\n",
      "Saved: dyn2_q1_027_21_conf0.90.png (112x72)\n",
      "Saved: dyn2_q1_028_12_conf0.92.png (120x208)\n",
      "Saved: dyn2_q1_029_12_conf0.94.png (120x208)\n",
      "Saved: dyn2_q1_030_12_conf0.95.png (120x200)\n",
      "\n",
      "Processed 31 predictions\n",
      "Cropped images saved to: /home/peter/Desktop/yolov5/runs/detect/exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./best.pt'], source=/home/peter/dyn2/dyn2_q2.png, data=data/coco128.yaml, imgsz=[5000, 5000], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=cpu, view_img=False, save_txt=False, save_format=0, save_csv=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.0s\n",
      "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-430-g459d8bf0 Python-3.12.3 torch-2.8.0+cu128 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46280598 parameters, 0 gradients, 108.2 GFLOPs\n",
      "WARNING ⚠️ --img-size [5000, 5000] must be multiple of max stride 32, updating to [5024, 5024]\n",
      "image 1/1 /home/peter/dyn2/dyn2_q2.png: 3904x5024 3 4s, 1 6, 3 12s, 1 15, 1 20, 5 24s, 3 30s, 2 31s, 9605.5ms\n",
      "Speed: 14.3ms pre-process, 9605.5ms inference, 10.6ms NMS per image at shape (1, 3, 5024, 5024)\n",
      "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: dyn2_q2_000_31_conf0.64.png (384x288)\n",
      "Saved: dyn2_q2_001_24_conf0.65.png (168x112)\n",
      "Saved: dyn2_q2_002_15_conf0.71.png (208x144)\n",
      "Saved: dyn2_q2_003_31_conf0.74.png (408x400)\n",
      "Saved: dyn2_q2_004_24_conf0.75.png (76x104)\n",
      "Saved: dyn2_q2_005_24_conf0.77.png (104x184)\n",
      "Saved: dyn2_q2_006_30_conf0.79.png (176x176)\n",
      "Saved: dyn2_q2_007_30_conf0.82.png (128x128)\n",
      "Saved: dyn2_q2_008_24_conf0.83.png (160x104)\n",
      "Saved: dyn2_q2_009_12_conf0.83.png (216x120)\n",
      "Saved: dyn2_q2_010_12_conf0.83.png (216x120)\n",
      "Saved: dyn2_q2_011_24_conf0.85.png (45x120)\n",
      "Saved: dyn2_q2_012_6_conf0.87.png (112x216)\n",
      "Saved: dyn2_q2_013_4_conf0.88.png (208x120)\n",
      "Saved: dyn2_q2_014_20_conf0.89.png (120x112)\n",
      "Saved: dyn2_q2_015_30_conf0.91.png (208x203)\n",
      "Saved: dyn2_q2_016_4_conf0.92.png (120x216)\n",
      "Saved: dyn2_q2_017_12_conf0.94.png (120x208)\n",
      "Saved: dyn2_q2_018_4_conf0.94.png (81x208)\n",
      "\n",
      "Processed 19 predictions\n",
      "Cropped images saved to: /home/peter/Desktop/yolov5/runs/detect/exp2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./best.pt'], source=/home/peter/dyn2/dyn2_q3.png, data=data/coco128.yaml, imgsz=[5000, 5000], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=cpu, view_img=False, save_txt=False, save_format=0, save_csv=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.0s\n",
      "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 v7.0-430-g459d8bf0 Python-3.12.3 torch-2.8.0+cu128 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 267 layers, 46280598 parameters, 0 gradients, 108.2 GFLOPs\n",
      "WARNING ⚠️ --img-size [5000, 5000] must be multiple of max stride 32, updating to [5024, 5024]\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "#pdf_file = \"/home/peter/ML101620329.pdf\"\n",
    "#pdf_file = \"/home/peter/PD637-A-2010-1-Model.pdf\"\n",
    "pdf_file = \"/home/peter/dyn2.pdf\"\n",
    "\n",
    "page = 0\n",
    "\n",
    "ollama_model = 'gemma3:27b'\n",
    "\n",
    "output_dir = pdf_file[:-4]\n",
    "filename = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "create_quads(pdf_file,page,output_dir) #create PNG files\n",
    "\n",
    "# Call Gemma3:27b via Ollama to get metadata\n",
    "prompt = \"\"\"List the project name, company name, drawing (DWG) name, drawing number, location, date, revision, author, \n",
    "and any other information found in the title block in the lower right corner of the image. Return data as JSON.\"\"\"\n",
    "png_path = output_dir+\"/\"+filename+\"_q4.png\"\n",
    "drawing_info = query_ollama(ollama_model, prompt, png_path,\"JSON\")\n",
    "\n",
    "# Call Claude and get line list. Need to send all 4 quadrants\n",
    "full_dwg = [] #all 4 quadrants\n",
    "for i in range(4):\n",
    "    n = i+1\n",
    "    full_dwg.append(output_dir+\"/\"+filename+\"_q\"+str(n)+\".png\")\n",
    "prompt = \"\"\"list the pipe lines on this P&ID with the line number, primary size, and what equipment, off-page connectors, \n",
    "or other lines it is connected to. Return the data as JSON and only return JSON.\"\"\"\n",
    "result = upload_multiple_images_to_claude(full_dwg, prompt)\n",
    "#TODO: there is a limit to the length of result, probably due to token limit. If there are more than 30 lines on the dwg, it will fail. \n",
    "line_list = json.loads(result[8:-4])\n",
    "\n",
    "#equipment list\n",
    "prompt = \"\"\"List the equipment on this P&ID with the name, description and associated metadata. Only list the primary equipment. \n",
    "Do not list piping, valves, instruments or information about the drawing itself. Return data as JSON\"\"\"\n",
    "result = upload_multiple_images_to_claude(full_dwg, prompt)\n",
    "equip_list = json.loads(result[8:-4])\n",
    "\n",
    "#Valves\n",
    "valves = []\n",
    "#clean up previous runs\n",
    "try:\n",
    "    detect_path = \"/home/peter/Desktop/yolov5/runs/detect\"\n",
    "    shutil.rmtree(detect_path)\n",
    "except FileNotFoundError :\n",
    "    pass    #don't sweat it if the directory doesn't exist (anymore)\n",
    "\n",
    "# go through each prediction and add the right info to the valve list\n",
    "#process_valves(valves,full_dwg,detect_path)\n",
    "process_valves_instruments(\"valve\",valves,full_dwg,detect_path)\n",
    "#Instruments\n",
    "instruments = []\n",
    "process_valves_instruments(\"inst\",instruments,full_dwg,detect_path)\n",
    "\n",
    "#Put it all together\n",
    "generator = DEXPIGenerator()\n",
    "root = generator.create_dexpi_xml(\n",
    "    pipes=line_list['pipelines'],\n",
    "    equipment=equip_list['equipment'],\n",
    "    valves=valves,\n",
    "    instruments=instruments,\n",
    "    drawing_metadata=drawing_info\n",
    ")\n",
    "    \n",
    "output_path = os.path.join(os.path.dirname(pdf_file), filename + '.xml')\n",
    "generator.save_xml(root, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b79a73c6-5d0b-469f-a7b2-215087e3f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEXPI XML saved to /home/peter/PD637-A-2010-1-Model.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273607/143523401.py:93: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  ET.SubElement(timestamp, 'DateTime').text = datetime.utcnow().isoformat() + 'Z'\n"
     ]
    }
   ],
   "source": [
    "#Put it all together\n",
    "generator = DEXPIGenerator()\n",
    "root = generator.create_dexpi_xml(\n",
    "    pipes=line_list['pipelines'],\n",
    "    equipment=equip_list['equipment'],\n",
    "    valves=valves,\n",
    "    instruments=instruments,\n",
    "    drawing_metadata=drawing_info\n",
    ")\n",
    "    \n",
    "output_path = os.path.join(os.path.dirname(pdf_file), filename + '.xml')\n",
    "generator.save_xml(root, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0126f7c2-b0d9-4822-a453-f4aab984ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipelines': [{'line_number': '637BD20015-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2001-2', '637C-2001A']}, {'line_number': '637BD20016-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2002-2', '637C-2001A']}, {'line_number': '637BD20063-2\"-HS', 'primary_size': '2\"', 'connections': ['637C-2001A', '637BD20064-2\"-HS']}, {'line_number': '637BD20064-2\"-HS', 'primary_size': '2\"', 'connections': ['637BD20063-2\"-HS', '637BD20017-6\"-HS']}, {'line_number': '637BD20017-6\"-HS', 'primary_size': '6\"', 'connections': ['637BD20064-2\"-HS', '637C-2001A']}, {'line_number': '631LS30058-6\"-CS', 'primary_size': '6\"', 'connections': ['637C-2001A', 'atmospheric vent']}, {'line_number': '631LS30059-3\"-CS', 'primary_size': '3\"', 'connections': ['637C-2001A', '637BD20024-8\"-CS']}, {'line_number': '637BD20024-8\"-CS', 'primary_size': '8\"', 'connections': ['631LS30059-3\"-CS', '637C-2001A']}, {'line_number': '637BD20019-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2001-1', '637BD20020-2\"-HS']}, {'line_number': '637BD20020-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2002-1', '637BD20019-2\"-HS', '637BD20021-3\"-HS']}, {'line_number': '637BD20021-3\"-HS', 'primary_size': '3\"', 'connections': ['637BD20020-2\"-HS', 'free draining']}, {'line_number': '631LS30011-6\"-CS', 'primary_size': '6\"', 'connections': ['637C-2002A', 'PD631-A-3003-2']}, {'line_number': '631LC40059-2\"-CS', 'primary_size': '2\"', 'connections': ['637C-2002A', 'open drain to floor']}, {'line_number': '637BD20061-3\"-CS', 'primary_size': '3\"', 'connections': ['637C-2002A', 'PD631-A-8017-1']}, {'line_number': '637BD20022-3\"-CS', 'primary_size': '3\"', 'connections': ['637C-2001A', '637BD20058-3\"-CS']}, {'line_number': '637BD20058-3\"-CS', 'primary_size': '3\"', 'connections': ['637BD20022-3\"-CS', 'floor trench']}, {'line_number': '637BD20025-2\"-CS', 'primary_size': '2\"', 'connections': ['637GM-2001A', '637GM-2001B']}, {'line_number': '637BD20031-3\"-CS', 'primary_size': '3\"', 'connections': ['637GM-2001A', '637GM-2001B']}, {'line_number': '637BD20026-4\"-CS', 'primary_size': '4\"', 'connections': ['637GM-2001A', '637GM-2001B']}]}\n",
      "{'line_number': '637BD20015-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2001-2', '637C-2001A']}\n",
      "{'line_number': '637BD20016-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2002-2', '637C-2001A']}\n",
      "{'line_number': '637BD20063-2\"-HS', 'primary_size': '2\"', 'connections': ['637C-2001A', '637BD20064-2\"-HS']}\n",
      "{'line_number': '637BD20064-2\"-HS', 'primary_size': '2\"', 'connections': ['637BD20063-2\"-HS', '637BD20017-6\"-HS']}\n",
      "{'line_number': '637BD20017-6\"-HS', 'primary_size': '6\"', 'connections': ['637BD20064-2\"-HS', '637C-2001A']}\n",
      "{'line_number': '631LS30058-6\"-CS', 'primary_size': '6\"', 'connections': ['637C-2001A', 'atmospheric vent']}\n",
      "{'line_number': '631LS30059-3\"-CS', 'primary_size': '3\"', 'connections': ['637C-2001A', '637BD20024-8\"-CS']}\n",
      "{'line_number': '637BD20024-8\"-CS', 'primary_size': '8\"', 'connections': ['631LS30059-3\"-CS', '637C-2001A']}\n",
      "{'line_number': '637BD20019-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2001-1', '637BD20020-2\"-HS']}\n",
      "{'line_number': '637BD20020-2\"-HS', 'primary_size': '2\"', 'connections': ['PD637-A-2002-1', '637BD20019-2\"-HS', '637BD20021-3\"-HS']}\n",
      "{'line_number': '637BD20021-3\"-HS', 'primary_size': '3\"', 'connections': ['637BD20020-2\"-HS', 'free draining']}\n",
      "{'line_number': '631LS30011-6\"-CS', 'primary_size': '6\"', 'connections': ['637C-2002A', 'PD631-A-3003-2']}\n",
      "{'line_number': '631LC40059-2\"-CS', 'primary_size': '2\"', 'connections': ['637C-2002A', 'open drain to floor']}\n",
      "{'line_number': '637BD20061-3\"-CS', 'primary_size': '3\"', 'connections': ['637C-2002A', 'PD631-A-8017-1']}\n",
      "{'line_number': '637BD20022-3\"-CS', 'primary_size': '3\"', 'connections': ['637C-2001A', '637BD20058-3\"-CS']}\n",
      "{'line_number': '637BD20058-3\"-CS', 'primary_size': '3\"', 'connections': ['637BD20022-3\"-CS', 'floor trench']}\n",
      "{'line_number': '637BD20025-2\"-CS', 'primary_size': '2\"', 'connections': ['637GM-2001A', '637GM-2001B']}\n",
      "{'line_number': '637BD20031-3\"-CS', 'primary_size': '3\"', 'connections': ['637GM-2001A', '637GM-2001B']}\n",
      "{'line_number': '637BD20026-4\"-CS', 'primary_size': '4\"', 'connections': ['637GM-2001A', '637GM-2001B']}\n"
     ]
    }
   ],
   "source": [
    "print(line_list)\n",
    "for eq in line_list['pipelines']:\n",
    "    print(eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd019ef5-e1af-42a3-846e-203b2262edab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdrawing_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "print(drawing_info.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb467793-1388-4bbb-bccf-7f794ed361f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
